# news_catalyst_analyzer.py - v5.1 (Full Log Analyzer)
# This script analyzes the proprietary catalyst database (catalyst_log.jsonl)
# generated by the live bot. It correlates ALL logged news events with historical
# price data to find profitable, catalyst-driven trading opportunities.

import requests
import pandas as pd
import numpy as np
from datetime import datetime, timedelta, date, time as dt_time
from dateutil.relativedelta import relativedelta
from dotenv import load_dotenv
import os
import itertools
import matplotlib.pyplot as plt
import time
import json
import io

# --- SETUP & CONFIGURATION ---
load_dotenv()
ALPHA_VANTAGE_API_KEY = os.getenv("ALPHA_VANTAGE_API_KEY")
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))

# --- File Paths ---
CATALYST_LOG_FILE = os.path.join(SCRIPT_DIR, "catalyst_log.jsonl")
REPORT_DIR = os.path.join(SCRIPT_DIR, "news_backtests")
CHART_DIR = os.path.join(SCRIPT_DIR, "news_charts")
CACHE_DIR = os.path.join(SCRIPT_DIR, "cache") # For price data
os.makedirs(REPORT_DIR, exist_ok=True)
os.makedirs(CHART_DIR, exist_ok=True)
os.makedirs(CACHE_DIR, exist_ok=True)

# --- ANALYSIS & TRADING PARAMS ---
HP_TIME_PERIOD_MONTHS = 1  # How far back to fetch price data (set to 1 for faster testing)
TRADE_PROFIT_TARGETS = [15.0, 30.0, 50.0]
TRADE_STOP_LOSSES = [8.0, 12.0]

def load_catalyst_log(log_filepath: str) -> pd.DataFrame:
    """
    Loads the catalyst_log.jsonl file into a pandas DataFrame.
    """
    if not os.path.exists(log_filepath):
        print(f"CRITICAL: Log file not found at '{log_filepath}'. Please ensure the live bot is running and has logged events.")
        return pd.DataFrame()

    print(f"--- Loading catalyst database from '{os.path.basename(log_filepath)}'...")
    events = []
    with open(log_filepath, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                events.append(json.loads(line))
            except json.JSONDecodeError:
                print(f"Warning: Could not parse a line in the log file: {line.strip()}")
    
    if not events:
        return pd.DataFrame()

    df = pd.DataFrame(events)
    df['capture_timestamp_utc'] = pd.to_datetime(df['capture_timestamp_utc'])
    df = df.sort_values(by='capture_timestamp_utc').reset_index(drop=True)
    print(f"--- Successfully loaded {len(df)} events from the database. ---")
    return df

def get_av_intraday_data(ticker: str, month_date: date):
    """
    Fetches historical intraday data using a HYBRID approach.
    - Uses EXTENDED_HISTORY for past months to get pre-market data.
    - Uses STANDARD INTRADAY for the current month for reliability.
    """
    today = date.today()
    is_current_month = (month_date.year == today.year and month_date.month == today.month)

    # --- IF IT'S A PAST MONTH, use the powerful extended history endpoint ---
    if not is_current_month:
        slice_str = f"year{month_date.year}month{month_date.month}"
        cache_filename = f"{ticker}_{slice_str}_ext.csv"
        cache_filepath = os.path.join(CACHE_DIR, cache_filename)

        if os.path.exists(cache_filepath):
            df = pd.read_csv(cache_filepath, index_col='timestamp', parse_dates=True)
            if df.index.tz is None:
                df = df.tz_localize('America/New_York')
            else:
                df = df.tz_convert('America/New_York')
            return df

        params = {"function": "TIME_SERIES_INTRADAY_EXTENDED_HISTORY", "symbol": ticker, "interval": "5min", "slice": slice_str, "apikey": ALPHA_VANTAGE_API_KEY}
        try:
            response = requests.get("https://www.alphavantage.co/query", params=params, timeout=30)
            response.raise_for_status()
            if "Bad API call" in response.text or "invalid API call" in response.text or response.text.strip() == "":
                return pd.DataFrame()
            df = pd.read_csv(io.StringIO(response.text))
            if df.empty or 'time' not in df.columns:
                return pd.DataFrame()

            df = df.rename(columns={'time': 'timestamp', 'open': 'Open', 'high': 'High', 'low': 'Low', 'close': 'Close', 'volume': 'Volume'})
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df = df.set_index('timestamp')
            df = df.tz_localize('UTC').tz_convert('America/New_York')
            df = df.sort_index()
            df.to_csv(cache_filepath)
            return df
        except Exception:
            return pd.DataFrame()

    # --- IF IT'S THE CURRENT MONTH, use the reliable standard endpoint ---
    else:
        month_str = month_date.strftime('%Y-%m')
        cache_filename = f"{ticker}_{month_str.replace('-', '')}.csv"
        cache_filepath = os.path.join(CACHE_DIR, cache_filename)

        if os.path.exists(cache_filepath):
            df = pd.read_csv(cache_filepath, index_col='timestamp', parse_dates=True)
            if df.index.tz is None:
                df = df.tz_localize('America/New_York')
            else:
                df = df.tz_convert('America/New_York')
            return df
        
        params = {"function": "TIME_SERIES_INTRADAY", "symbol": ticker, "interval": "5min", "month": month_str, "outputsize": "full", "apikey": ALPHA_VANTAGE_API_KEY, "datatype": "json"}
        try:
            response = requests.get("https://www.alphavantage.co/query", params=params, timeout=30)
            response.raise_for_status(); data = response.json()
            if "Time Series (5min)" not in data:
                return pd.DataFrame()

            df = pd.DataFrame.from_dict(data['Time Series (5min)'], orient='index', dtype=float)
            df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']
            df.index.name = 'timestamp'
            df.index = pd.to_datetime(df.index)
            df = df.tz_localize('America/New_York')
            df = df.sort_index()
            df.to_csv(cache_filepath)
            return df
        except Exception:
            return pd.DataFrame()

def generate_trade_chart(trade_data: dict, historical_data: pd.DataFrame):
    """Generates and saves a chart for a single simulated trade."""
    try:
        ticker = trade_data['ticker']
        entry_date = trade_data['entry_date']
        strategy_str = f"PT{trade_data['profit_target']}_SL{trade_data['stop_loss']}"
        ticker_chart_dir = os.path.join(CHART_DIR, ticker)
        os.makedirs(ticker_chart_dir, exist_ok=True)
        
        filename = f"{ticker}_{entry_date.strftime('%Y%m%d_%H%M')}_{strategy_str}.png"
        filepath = os.path.join(ticker_chart_dir, filename)

        # Charting window: from 1 day before the news to 2 days after the exit
        chart_start_date = trade_data['news_timestamp'].floor('D') - pd.Timedelta(days=1)
        chart_end_date = trade_data['exit_date'].floor('D') + pd.Timedelta(days=2)
        
        plot_data = historical_data.loc[chart_start_date:chart_end_date]
        if plot_data.empty:
            print(f"  -- No plot data for ${ticker} in range {chart_start_date} to {chart_end_date}")
            return

        plt.style.use('dark_background')
        fig, ax = plt.subplots(figsize=(15, 8))
        
        ax.plot(plot_data.index, plot_data['Close'], label='Close Price (5min)', color='cyan', linewidth=1)
        ax.axvline(x=trade_data['news_timestamp'], color='yellow', linestyle='--', linewidth=2, label=f"News Event ({trade_data.get('source', 'Unknown')})")
        ax.plot(entry_date, trade_data['entry_price'], 'o', color='lime', markersize=10, label=f"Entry: ${trade_data['entry_price']:.2f}")
        ax.plot(trade_data['exit_date'], trade_data['exit_price'], 'x', color='red', markersize=12, label=f"Exit: ${trade_data['exit_price']:.2f}")

        title = f"{ticker} | {entry_date.strftime('%Y-%m-%d')} | {strategy_str}\nResult: {trade_data['pnl_pct']:+.2f}% ({trade_data['exit_reason']})"
        plt.suptitle(title, fontsize=16)
        plt.title(f"Catalyst: {trade_data['headline']}", fontsize=10, style='italic')
        
        ax.set_ylabel("Price ($)")
        ax.grid(True, linestyle='--', alpha=0.3)
        ax.legend()
        plt.xticks(rotation=45)
        plt.tight_layout(rect=[0, 0.03, 1, 0.95])
        
        plt.savefig(filepath)
        plt.close(fig)
    except Exception as e:
        print(f"  -- Could not generate chart for ${ticker}: {e}")

def save_report_to_csv(trade_results: list):
    """Saves the full list of trade simulation results to a CSV file."""
    if not trade_results:
        print("\nNo trade results to save.")
        return
        
    df = pd.DataFrame(trade_results)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"news_backtest_report_{timestamp}.csv"
    filepath = os.path.join(REPORT_DIR, filename)
    
    try:
        # --- NEW: Added 'peak_gain_pct' to the column list ---
        cols = ['ticker', 'news_timestamp', 'headline', 'pnl_pct', 'peak_gain_pct', 'exit_reason', 
                'profit_target', 'stop_loss', 'entry_price', 'exit_price', 'entry_date', 
                'exit_date', 'source']
        
        # Ensure all columns exist before trying to reorder
        df = df.reindex(columns=cols)
        
        df.to_csv(filepath, index=False)
        print(f"\n--- üíæ Report saved successfully to: {filepath} ---")
    except Exception as e:
        print(f"\n--- ‚ùå Error saving report to CSV: {e} ---")

def simulate_intraday_trade(intraday_price_data: pd.DataFrame, entry_date: pd.Timestamp, entry_price: float, pt: float, sl: float):
    """
    Simulates a trade and calculates peak potential gain.
    V3: Includes peak gain calculation.
    """
    stop_loss_price = entry_price * (1 - sl / 100)
    profit_target_price = entry_price * (1 + pt / 100)
    
    session_date = entry_date.date()
    market_open_time = datetime.combine(session_date, dt_time(9, 30)).replace(tzinfo=entry_date.tzinfo)
    market_close_time = datetime.combine(session_date, dt_time(16, 0)).replace(tzinfo=entry_date.tzinfo)

    if entry_date < market_open_time:
        trade_end_time = market_open_time
        exit_reason_if_no_hit = "Market Open"
    else:
        trade_end_time = market_close_time
        exit_reason_if_no_hit = "EOD"
    
    trade_slice = intraday_price_data[(intraday_price_data.index >= entry_date) & (intraday_price_data.index <= trade_end_time)]

    if trade_slice.empty:
        return {"status": "No Data"}

    # --- NEW: Calculate Peak Potential Gain ---
    peak_price = trade_slice['High'].max()
    peak_gain_pct = ((peak_price - entry_price) / entry_price) * 100

    for _, candle in trade_slice.iterrows():
        if candle['Low'] <= stop_loss_price:
            return {"status": "Success", "exit_price": stop_loss_price, "exit_date": candle.name, "exit_reason": "Stop-Loss", "pnl_pct": -sl, "peak_gain_pct": peak_gain_pct}
        if candle['High'] >= profit_target_price:
            return {"status": "Success", "exit_price": profit_target_price, "exit_date": candle.name, "exit_reason": "Profit-Target", "pnl_pct": pt, "peak_gain_pct": peak_gain_pct}

    last_candle = trade_slice.iloc[-1]
    pnl = ((last_candle['Close'] - entry_price) / entry_price) * 100
    return {"status": "Success", "exit_price": last_candle['Close'], "exit_date": last_candle.name, "exit_reason": exit_reason_if_no_hit, "pnl_pct": pnl, "peak_gain_pct": peak_gain_pct}

def run_log_analysis(catalyst_df: pd.DataFrame):
    """
    Main analysis function. (V3 - Peak Gain Aware)
    """
    if catalyst_df.empty:
        print("Catalyst log is empty. No analysis to perform.")
        return

    all_trade_results = []
    unique_tickers = catalyst_df['ticker'].unique()
    print(f"\n--- üî¨ Analyzing {len(catalyst_df)} events for {len(unique_tickers)} unique tickers (Extended Hours Mode) ---")
    
    for ticker in unique_tickers:
        print(f"\nProcessing ${ticker}...")
        
        full_intraday_data = pd.DataFrame()
        for i in range(HP_TIME_PERIOD_MONTHS):
            month_date = date.today() - relativedelta(months=i)
            monthly_data = get_av_intraday_data(ticker, month_date)
            if not monthly_data.empty:
                full_intraday_data = pd.concat([full_intraday_data, monthly_data])

        if full_intraday_data.empty:
            print(f"  -> No historical data available for ${ticker} from the API. Skipping.")
            continue
        
        full_intraday_data = full_intraday_data[~full_intraday_data.index.duplicated(keep='first')].sort_index()
        
        ticker_events = catalyst_df[catalyst_df['ticker'] == ticker]
        print(f"  -> Found {len(ticker_events)} logged events and price data for ${ticker}. Analyzing...")

        for _, event in ticker_events.iterrows():
            try:
                event_timestamp = event['capture_timestamp_utc'].tz_convert('America/New_York')
                param_grid = list(itertools.product(TRADE_PROFIT_TARGETS, TRADE_STOP_LOSSES))
                entry_candle_slice = full_intraday_data[full_intraday_data.index >= event_timestamp]
                
                if entry_candle_slice.empty:
                    continue
                
                entry_price = entry_candle_slice.iloc[0]['Open']
                entry_date = entry_candle_slice.iloc[0].name

                if pd.isna(entry_price) or entry_price == 0:
                    continue

                for pt, sl in param_grid:
                    trade_result = simulate_intraday_trade(full_intraday_data, entry_date, entry_price, pt, sl)
                    
                    if trade_result['status'] == "Success":
                        # This dictionary structure is now updated to match the simulator's output
                        full_trade_data = {
                            "ticker": ticker, "news_timestamp": event_timestamp, "headline": event['headline'],
                            "source": event.get('source', 'Unknown'), "profit_target": pt, "stop_loss": sl,
                            "entry_price": entry_price, "entry_date": entry_date, "exit_date": trade_result['exit_date'],
                            "exit_price": trade_result['exit_price'], "exit_reason": trade_result['exit_reason'],
                            "pnl_pct": trade_result['pnl_pct'], "peak_gain_pct": trade_result['peak_gain_pct']
                        }
                        all_trade_results.append(full_trade_data)
                        generate_trade_chart(full_trade_data, full_intraday_data)
            except Exception as e:
                print(f"    -> An error occurred processing event for ${ticker}: {e}")

    save_report_to_csv(all_trade_results)

if __name__ == "__main__":
    catalyst_data = load_catalyst_log(CATALYST_LOG_FILE)
    if not catalyst_data.empty:
        run_log_analysis(catalyst_data)
    else:
        print("Exiting: Catalyst log file is empty or could not be loaded.")
